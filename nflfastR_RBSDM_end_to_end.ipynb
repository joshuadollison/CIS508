{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0233f1f6",
   "metadata": {},
   "source": [
    "# NFL Game Outcome Modeling: nflfastR + RBSDM EPA\n",
    "\n",
    "This notebook pulls **nflfastR** play-by-play using `nfl_data_py`, joins **RBSDM** team EPA/play summaries, and builds a clean game-level dataset.  It trains two models - **Logistic Regression** and **Gradient Boosting** - and compares their performance.  It also outputs **win probabilities** for a selected week.  Two spaces after periods here by your preference.  \n",
    "\n",
    "**Data sources:**  \n",
    "- nflverse / nflfastR play-by-play via `nfl_data_py`.  \n",
    "- RBSDM team EPA/play CSV.  \n",
    "\n",
    "**Sections:**  \n",
    "1. Setup and installs  \n",
    "2. Load data  \n",
    "3. Feature engineering and lagged team-week aggregates  \n",
    "4. Merge to game-level rows  \n",
    "5. Train Logistic Regression and Gradient Boosting  \n",
    "6. Evaluate, compare, and interpret  \n",
    "7. Predict win probabilities for a given week  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99aa09",
   "metadata": {},
   "source": [
    "## 1. Setup and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a718120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (1.3.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (1.23.3)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (3.6.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (2.32.5)\n",
      "Collecting nfl_data_py\n",
      "  Downloading nfl_data_py-0.3.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from scikit-learn) (1.9.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from requests) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from requests) (2023.11.17)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting appdirs>1 (from nfl_data_py)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting fastparquet>0.5 (from nfl_data_py)\n",
      "  Downloading fastparquet-2024.11.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting cramjam>=2.3 (from fastparquet>0.5->nfl_data_py)\n",
      "  Downloading cramjam-2.11.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: fsspec in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from fastparquet>0.5->nfl_data_py) (2025.9.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joshuadollison/miniforge3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.25.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "Downloading matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nfl_data_py-0.3.3-py3-none-any.whl (13 kB)\n",
      "Downloading pandas-1.5.3-cp39-cp39-macosx_11_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading fastparquet-2024.11.0-cp39-cp39-macosx_11_0_arm64.whl (684 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.7/684.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "Downloading cramjam-2.11.0-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading numpy-1.25.2-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: appdirs, threadpoolctl, numpy, joblib, cramjam, pandas, scikit-learn, matplotlib, fastparquet, nfl_data_py\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.23.3\n",
      "\u001b[2K    Uninstalling numpy-1.23.3:\n",
      "\u001b[2K      Successfully uninstalled numpy-1.23.3━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/10\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: pandas\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: pandas 1.3.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/10\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling pandas-1.3.4:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-1.3.4[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.6.1━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling matplotlib-3.6.1:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.6.1[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 7/10\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [nfl_data_py]\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed appdirs-1.4.4 cramjam-2.11.0 fastparquet-2024.11.0 joblib-1.5.2 matplotlib-3.9.4 nfl_data_py-0.3.3 numpy-1.24.3 pandas-1.5.1 scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If running locally, uncomment as needed.\n",
    "%pip install -U pandas numpy scikit-learn matplotlib requests nfl_data_py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f76237",
   "metadata": {},
   "source": [
    "## 2. Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# nfl_data_py imports\n",
    "from nfl_data_py import import_pbp_data, import_schedules\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# Plot defaults\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55406fa3",
   "metadata": {},
   "source": [
    "## 3. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasons to include for training.  Adjust as desired.\n",
    "SEASONS = list(range(2019, 2025))  # 2019–2024\n",
    "\n",
    "# Week to predict (example).  Must exist in the selected seasons.\n",
    "PREDICT_SEASON = 2024\n",
    "PREDICT_WEEK = 10  # change to the week you want probabilities for\n",
    "\n",
    "# RBSDM stats CSV endpoint.  If the path changes, update here.\n",
    "RBSDM_URL = \"https://rbsdm.com/stats/stats.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7618def",
   "metadata": {},
   "source": [
    "## 4. Load play-by-play and schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c58648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull play-by-play for selected seasons\n",
    "pbp = import_pbp_data(SEASONS)\n",
    "\n",
    "# Keep regular plays only\n",
    "pbp = pbp.loc[pbp[\"play_type\"].notna()].copy()\n",
    "\n",
    "# Pull schedules for outcomes and basic game info\n",
    "sched = import_schedules(SEASONS)\n",
    "\n",
    "# Outcome label: home team win as 1, else 0\n",
    "sched = sched.assign(\n",
    "    home_win = (sched[\"result\"] > 0).astype(int)\n",
    ")\n",
    "\n",
    "# Keep necessary columns\n",
    "sched_small = sched[[\n",
    "    \"game_id\",\"season\",\"week\",\n",
    "    \"home_team\",\"away_team\",\"home_score\",\"away_score\",\"home_win\",\"game_type\"\n",
    "]].copy()\n",
    "\n",
    "# Filter to regular season only for modeling unless you want playoffs\n",
    "sched_small = sched_small.loc[sched_small[\"game_type\"] == \"REG\"].reset_index(drop=True)\n",
    "\n",
    "sched_small.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80db875",
   "metadata": {},
   "source": [
    "## 5. Team-week aggregates and lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42feced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offense-side aggregates by posteam and (season, week)\n",
    "off_agg = (\n",
    "    pbp.groupby([\"season\",\"week\",\"posteam\"], as_index=False)\n",
    "       .agg(\n",
    "           off_plays=(\"play_id\",\"count\"),\n",
    "           off_epa_mean=(\"epa\",\"mean\"),\n",
    "           off_success=(\"success\",\"mean\"),\n",
    "           off_yards_gained=(\"yards_gained\",\"mean\"),\n",
    "           off_pass_rate=(\"pass\",\"mean\"),\n",
    "           off_rush_rate=(\"rush\",\"mean\")\n",
    "       )\n",
    "       .rename(columns={\"posteam\":\"team\"})\n",
    ")\n",
    "\n",
    "# Defense-side aggregates by defteam and (season, week)\n",
    "def_agg = (\n",
    "    pbp.groupby([\"season\",\"week\",\"defteam\"], as_index=False)\n",
    "       .agg(\n",
    "           def_plays=(\"play_id\",\"count\"),\n",
    "           def_epa_mean=(\"epa\",\"mean\"),\n",
    "           def_success=(\"success\",\"mean\"),\n",
    "           def_yards_gained=(\"yards_gained\",\"mean\"),\n",
    "           def_pass_rate=(\"pass\",\"mean\"),\n",
    "           def_rush_rate=(\"rush\",\"mean\")\n",
    "       )\n",
    "       .rename(columns={\"defteam\":\"team\"})\n",
    ")\n",
    "\n",
    "team_week = pd.merge(off_agg, def_agg, on=[\"season\",\"week\",\"team\"], how=\"outer\")\n",
    "\n",
    "# Add rolling (lagged) features per team up to the prior week to avoid leakage\n",
    "def add_group_rolls(df, group_col=\"team\"):\n",
    "    df = df.sort_values([\"season\",\"week\"]).copy()\n",
    "    # For rolling across seasons, create a continuous counter by team\n",
    "    df[\"season_week_index\"] = (df[\"season\"] - df[\"season\"].min()) * 18 + df[\"week\"]\n",
    "    df = df.sort_values([group_col, \"season_week_index\"])\n",
    "\n",
    "    num_cols = [c for c in df.columns if c not in [group_col,\"season\",\"week\",\"season_week_index\"]]\n",
    "\n",
    "    for col in num_cols:\n",
    "        # shift by 1 to exclude current week, then rolling means over last N weeks\n",
    "        df[f\"{col}_lag1\"] = df.groupby(group_col)[col].shift(1)\n",
    "        df[f\"{col}_roll3\"] = df.groupby(group_col)[col].shift(1).rolling(3).mean()\n",
    "        df[f\"{col}_roll5\"] = df.groupby(group_col)[col].shift(1).rolling(5).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "team_week = add_group_rolls(team_week, \"team\")\n",
    "\n",
    "# Keep only lagged/rolling features to avoid leakage\n",
    "lag_cols = [c for c in team_week.columns if c.endswith((\"_lag1\",\"_roll3\",\"_roll5\"))]\n",
    "base_cols = [\"season\",\"week\",\"team\"]\n",
    "team_week_lagged = team_week[base_cols + lag_cols].copy()\n",
    "\n",
    "team_week_lagged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779793d6",
   "metadata": {},
   "source": [
    "## 6. RBSDM team EPA/play and team-name harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download RBSDM team stats\n",
    "r = requests.get(RBSDM_URL, timeout=30)\n",
    "r.raise_for_status()\n",
    "rbsdm = pd.read_csv(io.StringIO(r.text))\n",
    "\n",
    "# Keep a few useful columns if available\n",
    "possible_cols = [c for c in rbsdm.columns if c.lower() in {\n",
    "    \"team\",\"season\",\"off_epa\",\"def_epa\",\"off_success\",\"def_success\",\"off_pass_epa\",\"off_rush_epa\",\"def_pass_epa\",\"def_rush_epa\"\n",
    "}]\n",
    "if \"team\" not in possible_cols:\n",
    "    possible_cols = [\"team\",\"season\",\"off_epa\",\"def_epa\",\"off_success\",\"def_success\",\"off_pass_epa\",\"off_rush_epa\",\"def_pass_epa\",\"def_rush_epa\"]\n",
    "rbsdm_small = rbsdm[[c for c in possible_cols if c in rbsdm.columns]].copy()\n",
    "\n",
    "# Team mapping between abbreviations and full names for current franchises\n",
    "abbr_to_full = {\n",
    "    \"ARI\":\"Arizona Cardinals\",\"ATL\":\"Atlanta Falcons\",\"BAL\":\"Baltimore Ravens\",\"BUF\":\"Buffalo Bills\",\n",
    "    \"CAR\":\"Carolina Panthers\",\"CHI\":\"Chicago Bears\",\"CIN\":\"Cincinnati Bengals\",\"CLE\":\"Cleveland Browns\",\n",
    "    \"DAL\":\"Dallas Cowboys\",\"DEN\":\"Denver Broncos\",\"DET\":\"Detroit Lions\",\"GB\":\"Green Bay Packers\",\n",
    "    \"HOU\":\"Houston Texans\",\"IND\":\"Indianapolis Colts\",\"JAX\":\"Jacksonville Jaguars\",\"KC\":\"Kansas City Chiefs\",\n",
    "    \"LV\":\"Las Vegas Raiders\",\"LAC\":\"Los Angeles Chargers\",\"LAR\":\"Los Angeles Rams\",\"MIA\":\"Miami Dolphins\",\n",
    "    \"MIN\":\"Minnesota Vikings\",\"NE\":\"New England Patriots\",\"NO\":\"New Orleans Saints\",\"NYG\":\"New York Giants\",\n",
    "    \"NYJ\":\"New York Jets\",\"PHI\":\"Philadelphia Eagles\",\"PIT\":\"Pittsburgh Steelers\",\"SEA\":\"Seattle Seahawks\",\n",
    "    \"SF\":\"San Francisco 49ers\",\"TB\":\"Tampa Bay Buccaneers\",\"TEN\":\"Tennessee Titans\",\"WAS\":\"Washington Commanders\"\n",
    "}\n",
    "\n",
    "# Create a team mapping table for joining\n",
    "teams_map = pd.DataFrame({\n",
    "    \"team\": list(abbr_to_full.keys()),\n",
    "    \"team_full\": list(abbr_to_full.values())\n",
    "})\n",
    "\n",
    "# RBSDM uses a \"team\" name string.  Normalize with the full names where possible.\n",
    "if \"team\" in rbsdm_small.columns:\n",
    "    rbsdm_small = rbsdm_small.rename(columns={\"team\":\"team_full\"})\n",
    "else:\n",
    "    rbsdm_small[\"team_full\"] = None  # fallback\n",
    "\n",
    "# Join RBSDM to lagged team-week on full names\n",
    "team_week_enriched = team_week_lagged.merge(teams_map, on=\"team\", how=\"left\").merge(\n",
    "    rbsdm_small, on=[\"team_full\",\"season\"], how=\"left\"\n",
    ")\n",
    "\n",
    "team_week_enriched.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c2032",
   "metadata": {},
   "source": [
    "## 7. Assemble game-level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701dd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each game, attach home team features and away team features from prior week aggregates\n",
    "def join_side(team_key_prefix, team_col_name):\n",
    "    side = team_week_enriched.copy()\n",
    "    side = side.rename(columns={\n",
    "        \"team\": f\"{team_key_prefix}_team\"\n",
    "    })\n",
    "    # Add prefixes to feature columns\n",
    "    side_feat_cols = [c for c in side.columns if c not in [\"season\",\"week\",f\"{team_key_prefix}_team\",\"team_full\"]]\n",
    "    side = side.rename(columns={c: f\"{team_key_prefix}_{c}\" for c in side_feat_cols})\n",
    "    return side\n",
    "\n",
    "home_side = join_side(\"home\", \"home_team\")\n",
    "away_side = join_side(\"away\", \"away_team\")\n",
    "\n",
    "games = sched_small.merge(\n",
    "    home_side, left_on=[\"season\",\"week\",\"home_team\"], right_on=[\"season\",\"week\",\"home_team\"], how=\"left\"\n",
    ").merge(\n",
    "    away_side, left_on=[\"season\",\"week\",\"away_team\"], right_on=[\"season\",\"week\",\"away_team\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Target\n",
    "games[\"y_home_win\"] = games[\"home_win\"].astype(int)\n",
    "\n",
    "# Drop rows with no features (early weeks may lack lags)\n",
    "feature_cols = [c for c in games.columns if any(c.startswith(p) for p in [\"home_\",\"away_\"])]\n",
    "X = games[feature_cols].copy()\n",
    "y = games[\"y_home_win\"].copy()\n",
    "\n",
    "# Remove columns that are purely identifiers or non-numeric\n",
    "X = X.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Drop columns with too many missing values\n",
    "min_non_na = int(0.8 * len(X))\n",
    "keep_cols = [c for c in X.columns if X[c].notna().sum() >= min_non_na]\n",
    "X = X[keep_cols]\n",
    "games = games.assign(valid_row = X.notna().all(axis=1))\n",
    "mask = games[\"valid_row\"].values\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "games_valid = games[mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total games with features: {len(games_valid)} of {len(games)}\")\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0851988",
   "metadata": {},
   "source": [
    "## 8. Train and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aac193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a season-aware split: train on seasons before the max-1, test on the last season in the set\n",
    "last_season = max(SEASONS)\n",
    "train_mask = games_valid[\"season\"] < last_season\n",
    "test_mask  = games_valid[\"season\"] == last_season\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}  |  Train seasons <= {last_season-1}, Test season == {last_season}\")\n",
    "\n",
    "# Logistic Regression with scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "logit = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "logit_proba = logit.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_proba = gb.predict_proba(X_test)[:,1]\n",
    "\n",
    "def eval_metrics(y_true, y_pred_proba, threshold=0.5, label=\"model\"):\n",
    "    auc  = roc_auc_score(y_true, y_pred_proba)\n",
    "    brier = brier_score_loss(y_true, y_pred_proba)\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\"label\": label, \"AUC\": auc, \"Brier\": brier, \"Accuracy@0.5\": acc}\n",
    "\n",
    "res = []\n",
    "res.append(eval_metrics(y_test, logit_proba, label=\"Logistic Regression\"))\n",
    "res.append(eval_metrics(y_test, gb_proba, label=\"Gradient Boosting\"))\n",
    "pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df5004",
   "metadata": {},
   "source": [
    "## 9. Feature importance and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b797fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression coefficients (top magnitude)\n",
    "coef_series = pd.Series(logit.coef_[0], index=X_train.columns)\n",
    "top_coef = coef_series.reindex(coef_series.abs().sort_values(ascending=False).head(20).index)\n",
    "\n",
    "plt.figure()\n",
    "top_coef.sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Feature importance vs Log-odds (Logistic Regression)\")\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Permutation importance for Gradient Boosting\n",
    "perm = permutation_importance(gb, X_test, y_test, n_repeats=10, random_state=42)\n",
    "perm_imp = pd.Series(perm.importances_mean, index=X_train.columns).sort_values(ascending=False).head(20)\n",
    "\n",
    "plt.figure()\n",
    "perm_imp.sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Permutation importance (Gradient Boosting)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a0099",
   "metadata": {},
   "source": [
    "## 10. Predict win probabilities for a given week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e76f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the target week in PREDICT_SEASON and PREDICT_WEEK\n",
    "target_games = games_valid[(games_valid[\"season\"] == PREDICT_SEASON) & (games_valid[\"week\"] == PREDICT_WEEK)].copy()\n",
    "target_X = target_games[X.columns].copy()\n",
    "\n",
    "# Scale for logistic\n",
    "target_X_scaled = scaler.transform(target_X)\n",
    "\n",
    "target_games[\"proba_home_logit\"] = logit.predict_proba(target_X_scaled)[:,1]\n",
    "target_games[\"proba_home_gb\"] = gb.predict_proba(target_X)[:,1]\n",
    "target_games[\"pick_logit_home\"] = (target_games[\"proba_home_logit\"] >= 0.5).astype(int)\n",
    "target_games[\"pick_gb_home\"] = (target_games[\"proba_home_gb\"] >= 0.5).astype(int)\n",
    "\n",
    "cols_show = [\"season\",\"week\",\"home_team\",\"away_team\",\"home_win\",\"proba_home_logit\",\"proba_home_gb\",\"pick_logit_home\",\"pick_gb_home\"]\n",
    "target_games[cols_show].sort_values([\"week\",\"home_team\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1cfc3",
   "metadata": {},
   "source": [
    "## 11. Calibration and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd10d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter comparison of model probabilities (independent vs. dependent order: Logistic vs GradientBoosting)\n",
    "plt.figure()\n",
    "plt.scatter(logit_proba, gb_proba, alpha=0.6)\n",
    "plt.xlabel(\"Logistic Regression predicted probability\")\n",
    "plt.ylabel(\"Gradient Boosting predicted probability\")\n",
    "plt.title(\"Logistic Regression vs Gradient Boosting predicted probabilities\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fdb9d4",
   "metadata": {},
   "source": [
    "## 12. Notes and caveats\n",
    "\n",
    "- Early weeks can have sparse lag features.  Consider requiring at least three prior weeks or backfilling with priors.  \n",
    "- RBSDM stats are team-season level here.  You can extend to team-week by scraping their weekly tables or computing directly from pbp.  \n",
    "- Try alternative models like XGBoost or LightGBM if you want stronger non-linear learners.  \n",
    "- Consider adding market-based priors (closing spreads, totals) to improve calibration.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniforge3]",
   "language": "python",
   "name": "conda-env-miniforge3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
