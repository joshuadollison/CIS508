{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20860bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4242d3",
   "metadata": {},
   "source": [
    "# Clean names and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target labels as described in Borowski & Chlebus (2021)\n",
    "merged[\"target_win\"] = (merged[\"finish_position\"] == 1).astype(int)\n",
    "merged[\"target_quinella\"] = (merged[\"finish_position\"] <= 2).astype(int)\n",
    "\n",
    "# Race-wise z-score standardization\n",
    "z_candidates = [\n",
    "    \"weight_lb\",\n",
    "    \"decimal_price\",\n",
    "    \"age\",\n",
    "    \"distance_behind\",\n",
    "    \"over_weight\",\n",
    "    \"out_handicap\",\n",
    "    \"rpr_rating\",\n",
    "    \"tr_rating\",\n",
    "    \"or_rating\",\n",
    "    \"race_runners\",\n",
    "    \"margin\",\n",
    "    \"race_distance\",\n",
    "    \"winning_time\",\n",
    "    \"prize_total\",\n",
    "]\n",
    "for col in z_candidates:\n",
    "    if col in merged.columns:\n",
    "        def _race_z(x):\n",
    "            std = x.std(ddof=0)\n",
    "            if std == 0 or np.isnan(std):\n",
    "                return pd.Series(np.zeros(len(x)), index=x.index)\n",
    "            return (x - x.mean()) / std\n",
    "        merged[f\"{col}_z\"] = merged.groupby(\"race_id\")[col].transform(_race_z)\n",
    "\n",
    "# Rolling history features per horse (last 3 races)\n",
    "window = 3\n",
    "merged = merged.sort_values([\"horse_id\", \"race_date\", \"race_time\", \"race_id\"])\n",
    "merged[\"mean_finish_pos_3\"] = merged.groupby(\"horse_id\")[\"finish_position\"].transform(\n",
    "    lambda x: x.shift().rolling(window).mean()\n",
    ")\n",
    "merged[\"top3_ratio_3\"] = merged.groupby(\"horse_id\")[\"finish_position\"].transform(\n",
    "    lambda x: (x.shift() <= 3).rolling(window).mean()\n",
    ")\n",
    "merged[\"avg_decimal_price_3\"] = merged.groupby(\"horse_id\")[\"decimal_price\"].transform(\n",
    "    lambda x: x.shift().rolling(window).mean()\n",
    ")\n",
    "if \"prize_total\" in merged.columns:\n",
    "    merged[\"total_prize_3\"] = merged.groupby(\"horse_id\")[\"prize_total\"].transform(\n",
    "        lambda x: x.shift().rolling(window).sum()\n",
    "    )\n",
    "\n",
    "history_cols = [\n",
    "    col\n",
    "    for col in [\"mean_finish_pos_3\", \"top3_ratio_3\", \"avg_decimal_price_3\", \"total_prize_3\"]\n",
    "    if col in merged.columns\n",
    "]\n",
    "for col in history_cols:\n",
    "    merged[col] = merged[col].fillna(0)\n",
    "\n",
    "# Assemble feature table\n",
    "identifier_cols = [\n",
    "    \"race_id\",\n",
    "    \"horse_id\",\n",
    "    \"horse_name\",\n",
    "    \"race_date\",\n",
    "    \"course\",\n",
    "    \"going\",\n",
    "    \"race_distance\",\n",
    "    \"trainer_name\",\n",
    "    \"jockey_name\",\n",
    "]\n",
    "identifier_cols = [col for col in identifier_cols if col in merged.columns]\n",
    "z_cols = [f\"{col}_z\" for col in z_candidates if f\"{col}_z\" in merged.columns]\n",
    "target_cols = [\"target_win\", \"target_quinella\"]\n",
    "\n",
    "feature_df = merged[identifier_cols + z_cols + history_cols + target_cols].copy()\n",
    "\n",
    "# Persist outputs alongside original data\n",
    "output_dir = Path(\"data\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "merged_path = output_dir / \"merged_horse_race_2019.csv\"\n",
    "feature_path = output_dir / \"feature_engineered_2019.csv\"\n",
    "merged.to_csv(merged_path, index=False)\n",
    "feature_df.to_csv(feature_path, index=False)\n",
    "\n",
    "print(f\"Merged dataset shape: {merged.shape}\")\n",
    "print(f\"Feature dataset shape: {feature_df.shape}\")\n",
    "print(\"Feature columns:\")\n",
    "print(feature_df.columns.tolist())\n",
    "if z_cols:\n",
    "    print(\"Sample standardized features:\")\n",
    "    print(feature_df[z_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb77ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74760cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfdcf49",
   "metadata": {},
   "source": [
    "# merge dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e261401",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'finish_position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n",
      "\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'finish_position'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n",
      "\u001b[1;32m     19\u001b[0m         df[col] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Target variables\u001b[39;00m\n",
      "\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_win\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinish_position\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;32m     23\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_quinella\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinish_position\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Per-race z-scores for numeric performance columns\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n",
      "\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n",
      "\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n",
      "\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'finish_position'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data\n",
    "#races_path = \"races_2019.csv\"\n",
    "#horses_path = \"horses_2019.csv\"\n",
    "#races_df = pd.read_csv(races_path)\n",
    "#horses_df = pd.read_csv(horses_path)\n",
    "\n",
    "# Merge race and horse data on race_id\n",
    "df = merged.merge(races_df, on=\"rid\", how=\"inner\", suffixes=(\"_horse\", \"_race\"))\n",
    "\n",
    "# Basic cleaning: ensure numeric conversions\n",
    "numeric_cols = [\"weight_carried\", \"odds\", \"draw\", \"age\", \"distance\", \"time\", \"prize\"]\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Target variables\n",
    "df[\"target_win\"] = (df[\"finish_position\"] == 1).astype(int)\n",
    "df[\"target_quinella\"] = (df[\"finish_position\"] <= 2).astype(int)\n",
    "\n",
    "# Per-race z-scores for numeric performance columns\n",
    "z_cols = [col for col in numeric_cols if col in df.columns]\n",
    "for col in z_cols:\n",
    "    df[f\"{col}_z\"] = df.groupby(\"rid\")[col].transform(\n",
    "        lambda x: (x - x.mean()) / x.std(ddof=0) if x.std(ddof=0) else 0\n",
    "    )\n",
    "\n",
    "# Historical features per horse: last 3 races\n",
    "window = 3\n",
    "df = df.sort_values([\"horse_id\", \"date\", \"rid\"])\n",
    "\n",
    "df[\"mean_finish_pos_3\"] = (\n",
    "    df.groupby(\"horse_id\")[\"finish_position\"].transform(lambda x: x.shift().rolling(window).mean())\n",
    ")\n",
    "df[\"top3_ratio_3\"] = (\n",
    "    df.groupby(\"horse_id\")[\"finish_position\"]\n",
    "    .transform(lambda x: (x.shift() <= 3).rolling(window).mean())\n",
    ")\n",
    "df[\"avg_odds_3\"] = (\n",
    "    df.groupby(\"horse_id\")[\"odds\"].transform(lambda x: x.shift().rolling(window).mean())\n",
    ")\n",
    "if \"prize\" in df.columns:\n",
    "    df[\"total_prize_3\"] = (\n",
    "        df.groupby(\"horse_id\")[\"prize\"].transform(lambda x: x.shift().rolling(window).sum())\n",
    "    )\n",
    "\n",
    "# Drop rows with missing essential data\n",
    "required_cols = [\"finish_position\", \"odds\"]\n",
    "df = df.dropna(subset=[col for col in required_cols if col in df.columns])\n",
    "\n",
    "# Select relevant columns for outputs\n",
    "identifier_cols = [\n",
    "    \"race_id\",\n",
    "    \"horse_id\",\n",
    "    \"horse_name\",\n",
    "    \"jockey\",\n",
    "    \"trainer\",\n",
    "    \"date\",\n",
    "    \"track\",\n",
    "    \"going\",\n",
    "]\n",
    "identifier_cols = [col for col in identifier_cols if col in df.columns]\n",
    "z_cols = [f\"{col}_z\" for col in z_cols]\n",
    "history_cols = [col for col in [\"mean_finish_pos_3\", \"top3_ratio_3\", \"avg_odds_3\", \"total_prize_3\"] if col in df.columns]\n",
    "target_cols = [\"target_win\", \"target_quinella\"]\n",
    "\n",
    "merged_cols = sorted(set(horses.columns).union(set(races.columns)))\n",
    "merged_df = df[merged_cols]\n",
    "features_df = df[identifier_cols + z_cols + history_cols + target_cols]\n",
    "\n",
    "# Save outputs\n",
    "merged_df.to_csv(\"merged_horse_race_2019.csv\", index=False)\n",
    "features_df.to_csv(\"feature_engineered_2019.csv\", index=False)\n",
    "\n",
    "# Summary output\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
    "print(f\"Feature dataset shape: {features_df.shape}\")\n",
    "print(\"Feature columns:\")\n",
    "print(features_df.columns.tolist())\n",
    "print(\"Sample standardized features:\")\n",
    "print(features_df[z_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d2cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
