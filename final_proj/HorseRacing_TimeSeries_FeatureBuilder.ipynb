{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Horse Racing Time‑Series Feature Builder\n",
    "\n",
    "This notebook expects your **final merged DataFrame** and adds leakage‑safe time‑series features at the horse, jockey, trainer, and race‑context levels.  All features are computed using only prior observations relative to each race date.  Configure your column names below.\n",
    "\n",
    "**Deliverables:**\n",
    "1. Enriched DataFrame with time‑series features.\n",
    "2. Saved outputs: `merged_timeseries.parquet` and `merged_timeseries.csv`.\n",
    "3. Quick sanity plots and summary tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration\n",
    "\n",
    "Set the field names used in your merged DataFrame.  If unknown, leave `None` and the notebook will attempt a best‑effort autodetection from common names.  Two spaces after a sentence is intentional to match project style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration: set your column names here ---\n",
    "CONFIG = {\n",
    "    \"date_col\": None,            # e.g., \"race_date\"\n",
    "    \"race_id_col\": None,         # e.g., \"race_id\"\n",
    "    \"horse_id_col\": None,        # e.g., \"horse_id\"\n",
    "    \"jockey_id_col\": None,       # e.g., \"jockey_id\"\n",
    "    \"trainer_id_col\": None,      # e.g., \"trainer_id\"\n",
    "    \"track_col\": None,           # e.g., \"track_code\" or \"venue\"\n",
    "    \"surface_col\": None,         # e.g., \"surface\"\n",
    "    \"distance_col\": None,        # numeric distance if available\n",
    "    \"class_col\": None,           # race class/grade if available\n",
    "    \"finish_col\": None,          # e.g., finish position\n",
    "    \"time_col\": None,            # race time or speed figure (numeric)\n",
    "    \"odds_col\": None,            # starting odds if present\n",
    "    \"target_col\": None           # your modeling target (e.g., win_flag or finish_position)\n",
    "}\n",
    "\n",
    "# If your final merged DataFrame is not already in memory as `merged`, set a path here:\n",
    "INPUT_PATH = None  # e.g., \"/mnt/data/merged.parquet\" or \"/mnt/data/merged.csv\"\n",
    "INPUT_FORMAT = \"parquet\"  # \"parquet\" or \"csv\"\n",
    "\n",
    "OUTPUT_PARQUET = \"merged_timeseries.parquet\"\n",
    "OUTPUT_CSV = \"merged_timeseries.csv\"\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _try_autoload(path, fmt):\n",
    "    if path is None:\n",
    "        return None\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {p}\")\n",
    "    if fmt.lower() == \"parquet\":\n",
    "        return pd.read_parquet(p)\n",
    "    elif fmt.lower() == \"csv\":\n",
    "        return pd.read_csv(p)\n",
    "    else:\n",
    "        raise ValueError(\"INPUT_FORMAT must be 'parquet' or 'csv'.\")\n",
    "\n",
    "# Load if not present\n",
    "if \"merged\" not in globals():\n",
    "    merged = _try_autoload(INPUT_PATH, INPUT_FORMAT)\n",
    "\n",
    "assert merged is not None, \"Provide `merged` in memory or set INPUT_PATH/INPUT_FORMAT.\"\n",
    "\n",
    "# Make a working copy\n",
    "df = merged.copy()\n",
    "print(f\"Loaded DataFrame shape: {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Autodetect and validate required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMONS = {\n",
    "    \"date_col\": [\"race_date\", \"date\", \"raceDate\", \"dt\", \"event_date\"],\n",
    "    \"race_id_col\": [\"race_id\", \"raceId\", \"race_key\", \"event_id\"],\n",
    "    \"horse_id_col\": [\"horse_id\", \"horseId\", \"runner_id\", \"equine_id\", \"horse\"],\n",
    "    \"jockey_id_col\": [\"jockey_id\", \"jockey\", \"rider_id\", \"rider\"],\n",
    "    \"trainer_id_col\": [\"trainer_id\", \"trainer\"],\n",
    "    \"track_col\": [\"track\", \"venue\", \"track_code\", \"course\"],\n",
    "    \"surface_col\": [\"surface\", \"going\"],\n",
    "    \"distance_col\": [\"distance\", \"dist\"],\n",
    "    \"class_col\": [\"class\", \"grade\", \"race_class\"],\n",
    "    \"finish_col\": [\"finish_position\", \"finish\", \"pos\", \"place\"],\n",
    "    \"time_col\": [\"speed_figure\", \"race_time\", \"time\", \"sr\", \"beyer\"],\n",
    "    \"odds_col\": [\"odds\", \"sp\", \"starting_price\"],\n",
    "    \"target_col\": [\"win_flag\", \"won\", \"target\", \"label\", \"finish_position\"]\n",
    "}\n",
    "\n",
    "cols_lower = {c.lower(): c for c in df.columns}\n",
    "\n",
    "def resolve_col(key):\n",
    "    if CONFIG.get(key) and CONFIG[key] in df.columns:\n",
    "        return CONFIG[key]\n",
    "    for cand in COMMONS.get(key, []):\n",
    "        if cand in df.columns:\n",
    "            return cand\n",
    "        if cand.lower() in cols_lower:\n",
    "            return cols_lower[cand.lower()]\n",
    "    return None\n",
    "\n",
    "RES = {k: resolve_col(k) for k in CONFIG.keys()}\n",
    "\n",
    "missing = [k for k,v in RES.items() if v is None and k in (\"date_col\",\"race_id_col\",\"horse_id_col\")]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required column(s): {missing}.  Set CONFIG[...] at the top.\")\n",
    "\n",
    "# Cast date\n",
    "df[RES[\"date_col\"]] = pd.to_datetime(df[RES[\"date_col\"]], errors=\"coerce\")\n",
    "\n",
    "# Sort by time to enforce leakage‑safety\n",
    "df = df.sort_values([RES[\"horse_id_col\"], RES[\"date_col\"], RES[\"race_id_col\"]]).reset_index(drop=True)\n",
    "\n",
    "print(\"Resolved columns:\")\n",
    "for k,v in RES.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Leakage‑safe time‑series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "DATE = RES[\"date_col\"]\n",
    "RID  = RES[\"race_id_col\"]\n",
    "HID  = RES[\"horse_id_col\"]\n",
    "JID  = RES[\"jockey_id_col\"]\n",
    "TID  = RES[\"trainer_id_col\"]\n",
    "TRACK= RES[\"track_col\"]\n",
    "SURF = RES[\"surface_col\"]\n",
    "DIST = RES[\"distance_col\"]\n",
    "CLASS= RES[\"class_col\"]\n",
    "FIN  = RES[\"finish_col\"]\n",
    "TIME = RES[\"time_col\"]\n",
    "ODDS = RES[\"odds_col\"]\n",
    "\n",
    "# Helper: safe lag within group\n",
    "def add_lags(group, cols, lags=(1,3,5)):\n",
    "    for c in cols:\n",
    "        if c and c in group and is_numeric_dtype(group[c]):\n",
    "            for L in lags:\n",
    "                group[f\"{c}_lag{L}\"] = group[c].shift(L)\n",
    "    return group\n",
    "\n",
    "# Helper: rolling stats within group\n",
    "def add_rolls(group, cols, windows=(3,5,10)):\n",
    "    for c in cols:\n",
    "        if c and c in group and is_numeric_dtype(group[c]):\n",
    "            for w in windows:\n",
    "                r = group[c].shift(1).rolling(w, min_periods=1)\n",
    "                group[f\"{c}_roll{w}_mean\"] = r.mean()\n",
    "                group[f\"{c}_roll{w}_std\"]  = r.std()\n",
    "                group[f\"{c}_roll{w}_min\"]  = r.min()\n",
    "                group[f\"{c}_roll{w}_max\"]  = r.max()\n",
    "    return group\n",
    "\n",
    "# Helper: exponentially‑weighted stats\n",
    "def add_ewm(group, cols, alphas=(0.3, 0.6)):\n",
    "    for c in cols:\n",
    "        if c and c in group and is_numeric_dtype(group[c]):\n",
    "            for a in alphas:\n",
    "                e = group[c].shift(1).ewm(alpha=a, adjust=False)\n",
    "                group[f\"{c}_ewm{int(a*100)}\"] = e.mean()\n",
    "    return group\n",
    "\n",
    "# Days since last race\n",
    "df[\"days_since_last_race\"] = df.groupby(HID)[DATE].diff().dt.days\n",
    "\n",
    "# Career counts to date\n",
    "df[\"starts_to_date\"] = df.groupby(HID).cumcount()\n",
    "\n",
    "# Horse form features (finish/time/odds)\n",
    "num_cols_horse = [c for c in [FIN, TIME, ODDS] if c and c in df]\n",
    "df = df.groupby(HID, group_keys=False).apply(add_lags, cols=num_cols_horse)\n",
    "df = df.groupby(HID, group_keys=False).apply(add_rolls, cols=num_cols_horse)\n",
    "df = df.groupby(HID, group_keys=False).apply(add_ewm, cols=num_cols_horse)\n",
    "\n",
    "# Rolling win rate if target is a binary win flag\n",
    "if RES[\"target_col\"] and RES[\"target_col\"] in df:\n",
    "    tgt = RES[\"target_col\"]\n",
    "    if is_numeric_dtype(df[tgt]):\n",
    "        for w in (3,5,10):\n",
    "            df[f\"winrate_roll{w}\"] = df.groupby(HID)[tgt].shift(1).rolling(w, min_periods=1).mean()\n",
    "\n",
    "# Jockey and trainer recent performance (win rates, avg finish/time)\n",
    "def recent_perf(df, group_key, base_cols, prefix):\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    # appearances to date\n",
    "    out[f\"{prefix}_starts_to_date\"] = df.groupby(group_key).cumcount()\n",
    "    for c in base_cols:\n",
    "        if c and c in df and is_numeric_dtype(df[c]):\n",
    "            for w in (5,10,20):\n",
    "                r = df.groupby(group_key)[c].shift(1).rolling(w, min_periods=1)\n",
    "                out[f\"{prefix}_{c}_roll{w}_mean\"] = r.mean()\n",
    "    if RES[\"target_col\"] and RES[\"target_col\"] in df and is_numeric_dtype(df[RES[\"target_col\"]]):\n",
    "        for w in (5,10,20):\n",
    "            r = df.groupby(group_key)[RES[\"target_col\"]].shift(1).rolling(w, min_periods=1)\n",
    "            out[f\"{prefix}_winrate_roll{w}\"] = r.mean()\n",
    "    return out\n",
    "\n",
    "j_base = [FIN, TIME]\n",
    "t_base = [FIN, TIME]\n",
    "\n",
    "if JID:\n",
    "    jp = recent_perf(df, JID, j_base, \"jky\")\n",
    "    df = pd.concat([df, jp], axis=1)\n",
    "\n",
    "if TID:\n",
    "    tp = recent_perf(df, TID, t_base, \"trn\")\n",
    "    df = pd.concat([df, tp], axis=1)\n",
    "\n",
    "# Race‑context moving baselines: track/surface/time\n",
    "if TRACK:\n",
    "    for c in [TIME, FIN]:\n",
    "        if c and c in df and is_numeric_dtype(df[c]):\n",
    "            for w in (50, 200):\n",
    "                r = df.groupby(TRACK)[c].shift(1).rolling(w, min_periods=10)\n",
    "                df[f\"{c}_{TRACK}_baseline_roll{w}\"] = r.mean()\n",
    "\n",
    "if SURF and TIME and TIME in df and is_numeric_dtype(df[TIME]):\n",
    "    r = df.groupby(SURF)[TIME].shift(1).rolling(100, min_periods=10)\n",
    "    df[f\"{TIME}_{SURF}_baseline_roll100\"] = r.mean()\n",
    "\n",
    "# Calendar/time‑based features\n",
    "df[\"race_dow\"] = df[DATE].dt.dayofweek\n",
    "df[\"race_month\"] = df[DATE].dt.month\n",
    "df[\"race_year\"] = df[DATE].dt.year\n",
    "df[\"race_weekofyear\"] = df[DATE].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Distance/class normalization if available\n",
    "if DIST and DIST in df and is_numeric_dtype(df[DIST]) and TIME and TIME in df and is_numeric_dtype(df[TIME]):\n",
    "    # pace‑like metric per unit distance\n",
    "    df[\"time_per_unit_distance\"] = df[TIME] / (df[DIST].replace(0, np.nan))\n",
    "    # rolling normalized by track\n",
    "    if TRACK:\n",
    "        r = df.groupby([TRACK])[ \"time_per_unit_distance\" ].shift(1).rolling(100, min_periods=10)\n",
    "        df[\"tpud_track_baseline_roll100\"] = r.mean()\n",
    "\n",
    "# Simple correlation context placeholder: correlation vs target using historical rows only (no NA drop leakage)\n",
    "corr_cols = [c for c in df.columns if c not in [DATE, RID, HID, JID, TID, TRACK, SURF] and is_numeric_dtype(df[c])]\n",
    "if RES[\"target_col\"] and RES[\"target_col\"] in df and is_numeric_dtype(df[RES['target_col']]):\n",
    "    corr = df[corr_cols + [RES[\"target_col\"]]].corr(numeric_only=True)[RES[\"target_col\"]].drop(RES[\"target_col\"], errors=\"ignore\")\n",
    "    corr = corr.sort_values(key=lambda s: s.abs(), ascending=False).head(30)\n",
    "    corr_context = corr.to_frame(\"corr_with_target\").reset_index().rename(columns={\"index\":\"feature\"})\n",
    "else:\n",
    "    corr_context = None\n",
    "\n",
    "print(\"Feature engineering complete.  Shape:\", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(OUTPUT_PARQUET, index=False)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved: {OUTPUT_PARQUET} and {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Quick summaries and sanity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic stats for newly created columns\n",
    "created_cols = [c for c in df.columns if c not in merged.columns]\n",
    "summary = df[created_cols].describe().T if created_cols else pd.DataFrame()\n",
    "summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# One example plot: distribution of days_since_last_race\n",
    "if \"days_since_last_race\" in df.columns:\n",
    "    plt.figure()\n",
    "    df[\"days_since_last_race\"].dropna().hist(bins=50)\n",
    "    plt.title(\"Days Since Last Race  -  Distribution\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Example of rolling win rate stability by starts_to_date buckets (if exists)\n",
    "if \"winrate_roll5\" in df.columns and \"starts_to_date\" in df.columns:\n",
    "    tmp = df[[\"starts_to_date\", \"winrate_roll5\"]].dropna()\n",
    "    if not tmp.empty:\n",
    "        tmp2 = tmp.groupby(pd.cut(tmp[\"starts_to_date\"], bins=[0,5,10,20,50,100,500], include_lowest=True))[\"winrate_roll5\"].mean()\n",
    "        plt.figure()\n",
    "        tmp2.plot(kind=\"bar\")\n",
    "        plt.title(\"Avg Win Rate (Roll5) by Career Starts\")\n",
    "        plt.xlabel(\"Career Starts Bucket\")\n",
    "        plt.ylabel(\"Average Win Rate\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}