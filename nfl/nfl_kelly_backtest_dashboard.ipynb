{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70fe8bf",
   "metadata": {},
   "source": [
    "# Kelly sizing, bankroll simulation, and historical ROI backtest\n",
    "\n",
    "This notebook extends your NFL modeling workflow with stake sizing and backtesting.  It adds:\n",
    "- Kelly Criterion position sizing from model probabilities and American odds.  \n",
    "- Bankroll simulation with configurable fractional Kelly and edge thresholds.  \n",
    "- Historical ROI backtest hooks that join predictions to a table of closing moneylines.  \n",
    "- Simple plots for bankroll growth and edge distribution.  \n",
    "\n",
    "Two spaces after periods.  Hyphens instead of em dashes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f845df",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7203633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# %pip install -U pandas numpy matplotlib\n",
    "import os, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths - adjust to your project layout\n",
    "PRED_DIR = \"./data/weekly_predictions\"   # where the previous notebook writes weekly CSVs\n",
    "HIST_LINES_CSV = \"./data/lines_historical.csv\"  # user-provided historical closing lines\n",
    "os.makedirs(\"./data\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca7868",
   "metadata": {},
   "source": [
    "## 2. Helpers - odds, implied probabilities, and kelly sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moneyline_to_prob(ml):\n",
    "    if ml is None or pd.isna(ml):\n",
    "        return np.nan\n",
    "    ml = float(ml)\n",
    "    if ml > 0:\n",
    "        return 100.0 / (ml + 100.0)\n",
    "    else:\n",
    "        return -ml / (-ml + 100.0)\n",
    "\n",
    "def american_to_decimal(ml):\n",
    "    ml = float(ml)\n",
    "    if ml > 0:\n",
    "        return 1.0 + ml / 100.0\n",
    "    else:\n",
    "        return 1.0 + 100.0 / abs(ml)\n",
    "\n",
    "def kelly_fraction(p, ml):\n",
    "    \"\"\"Kelly fraction for a binary bet using American moneyline.\n",
    "    p is model probability of the event you are backing.\n",
    "    ml is the American odds for that outcome.\n",
    "    Returns fraction of bankroll to wager.  Negative means no bet.\n",
    "    \"\"\"\n",
    "    if pd.isna(p) or pd.isna(ml):\n",
    "        return np.nan\n",
    "    b = american_to_decimal(ml) - 1.0  # net odds\n",
    "    q = 1.0 - p\n",
    "    k = (b * p - q) / b\n",
    "    return k\n",
    "\n",
    "def fractional_kelly(p, ml, fraction=0.5):\n",
    "    k = kelly_fraction(p, ml)\n",
    "    return max(0.0, fraction * k) if not pd.isna(k) else np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec43e2",
   "metadata": {},
   "source": [
    "## 3. Load weekly predictions and assemble a season-long table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_weekly_predictions(pred_dir=PRED_DIR):\n",
    "    files = []\n",
    "    for f in os.listdir(pred_dir):\n",
    "        if f.endswith(\".csv\") and f.startswith(\"predictions_\"):\n",
    "            files.append(os.path.join(pred_dir, f))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No prediction CSVs found.  Run the modeling notebook to generate weekly predictions.\")\n",
    "    frames = [pd.read_csv(fp) for fp in sorted(files)]\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "preds = load_all_weekly_predictions(PRED_DIR)\n",
    "print(f\"Loaded {len(preds)} prediction rows from {PRED_DIR}.\")\n",
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8048b5e",
   "metadata": {},
   "source": [
    "## 4. Load historical closing lines and join to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31480880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect schema:\n",
    "# season,week,home_team,away_team,ml_home,ml_away,closing_flag\n",
    "# closing_flag == 1 if row is the closing line.  Multiple books may exist - keep one row per matchup.\n",
    "def load_hist_lines(path=HIST_LINES_CSV):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Historical lines CSV not found at {path}.  Use the provided template to create one.\")\n",
    "    df = pd.read_csv(path)\n",
    "    required = {\"season\",\"week\",\"home_team\",\"away_team\",\"ml_home\",\"ml_away\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in historical lines: {missing}\")\n",
    "    # Deduplicate if multiple rows per matchup\n",
    "    df = df.drop_duplicates(subset=[\"season\",\"week\",\"home_team\",\"away_team\"])\n",
    "    return df\n",
    "\n",
    "hist = load_hist_lines(HIST_LINES_CSV)\n",
    "joined = preds.merge(hist, on=[\"season\",\"week\",\"home_team\",\"away_team\"], how=\"inner\")\n",
    "print(f\"Joined rows: {len(joined)}\")\n",
    "joined.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a388a",
   "metadata": {},
   "source": [
    "## 5. Compute implied probabilities and edges vs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af319ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied probabilities for home moneyline\n",
    "joined[\"impl_home\"] = joined[\"ml_home\"].apply(moneyline_to_prob)\n",
    "joined[\"impl_away\"] = joined[\"ml_away\"].apply(moneyline_to_prob)\n",
    "\n",
    "# Normalize two-way to remove vig if both sides exist\n",
    "s = joined[\"impl_home\"] + joined[\"impl_away\"]\n",
    "joined[\"impl_home_norm\"] = joined[\"impl_home\"] / s\n",
    "joined[\"impl_away_norm\"] = joined[\"impl_away\"] / s\n",
    "\n",
    "# Choose a model - default Gradient Boosting from your earlier notebook\n",
    "joined[\"p_model_home\"] = joined[\"proba_home_gb\"]\n",
    "joined[\"edge_home\"] = joined[\"p_model_home\"] - joined[\"impl_home_norm\"]\n",
    "\n",
    "joined[[\"season\",\"week\",\"home_team\",\"away_team\",\"p_model_home\",\"impl_home_norm\",\"edge_home\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28934d19",
   "metadata": {},
   "source": [
    "## 6. Bankroll simulation with fractional Kelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bankroll(df, kelly_fraction_use=0.5, min_edge=0.02, max_fraction=0.02, starting_bankroll=10000.0, bet_on=\"home\"):\n",
    "    \"\"\"Simulate bankroll over time using fractional Kelly on chosen side.\n",
    "    df must include: p_model_home, ml_home, home_win, season, week, home_team, away_team\n",
    "    bet_on: \"home\" places bets when p_model_home - implied > min_edge.\n",
    "    Returns a copy with stakes and pnl, and the bankroll curve.\n",
    "    \"\"\"\n",
    "    out = df.copy().sort_values([\"season\",\"week\",\"home_team\",\"away_team\"]).reset_index(drop=True)\n",
    "    bankroll = starting_bankroll\n",
    "    curve = [bankroll]\n",
    "    stakes = []\n",
    "    pnls = []\n",
    "\n",
    "    for _, r in out.iterrows():\n",
    "        p = r[\"p_model_home\"]\n",
    "        ml = r[\"ml_home\"]\n",
    "        edge = r[\"edge_home\"]\n",
    "\n",
    "        # Decide whether to bet\n",
    "        if pd.isna(p) or pd.isna(ml) or pd.isna(edge) or edge < min_edge:\n",
    "            stakes.append(0.0)\n",
    "            pnls.append(0.0)\n",
    "            curve.append(bankroll)\n",
    "            continue\n",
    "\n",
    "        f_kelly = fractional_kelly(p, ml, fraction=kelly_fraction_use)\n",
    "        f_kelly = min(max(f_kelly, 0.0), max_fraction)  # cap bet size\n",
    "\n",
    "        stake = bankroll * f_kelly\n",
    "        stakes.append(stake)\n",
    "\n",
    "        # Resolve PnL\n",
    "        if r[\"home_win\"] == 1:\n",
    "            ret = stake * (american_to_decimal(ml) - 1.0)\n",
    "        else:\n",
    "            ret = -stake\n",
    "\n",
    "        bankroll += ret\n",
    "        pnls.append(ret)\n",
    "        curve.append(bankroll)\n",
    "\n",
    "    out[\"stake\"] = stakes\n",
    "    out[\"pnl\"] = pnls\n",
    "    out[\"bankroll_after\"] = curve[1:]\n",
    "    return out, curve\n",
    "\n",
    "sim, curve = simulate_bankroll(joined, kelly_fraction_use=0.5, min_edge=0.02, max_fraction=0.02, starting_bankroll=10000.0)\n",
    "print(f\"Final bankroll: {curve[-1]:.2f}\")\n",
    "sim.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138aaee",
   "metadata": {},
   "source": [
    "## 7. Plots - bankroll curve and edge histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bankroll curve\n",
    "plt.figure()\n",
    "plt.plot(curve)\n",
    "plt.title(\"Bankroll over time - fractional Kelly\")\n",
    "plt.xlabel(\"Bet index\")\n",
    "plt.ylabel(\"Bankroll\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Edge histogram\n",
    "plt.figure()\n",
    "valid_edges = sim[\"edge_home\"].dropna()\n",
    "plt.hist(valid_edges, bins=30)\n",
    "plt.title(\"Edge distribution - model probability minus implied\")\n",
    "plt.xlabel(\"Edge\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a188cc",
   "metadata": {},
   "source": [
    "## 8. Backtest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_metrics(sim):\n",
    "    total_bets = (sim[\"stake\"] > 0).sum()\n",
    "    roi = sim[\"pnl\"].sum() / sim[\"stake\"].sum() if sim[\"stake\"].sum() > 0 else np.nan\n",
    "    hit_rate = (sim.loc[sim[\"stake\"] > 0, \"home_win\"] == 1).mean() if total_bets > 0 else np.nan\n",
    "    max_dd = (sim[\"bankroll_after\"].cummax() - sim[\"bankroll_after\"]).max()\n",
    "    return {\n",
    "        \"total_bets\": int(total_bets),\n",
    "        \"roi\": roi,\n",
    "        \"hit_rate\": hit_rate,\n",
    "        \"final_bankroll\": float(sim[\"bankroll_after\"].iloc[-1]) if len(sim) else np.nan,\n",
    "        \"max_drawdown\": float(max_dd) if not pd.isna(max_dd) else np.nan\n",
    "    }\n",
    "\n",
    "metrics = backtest_metrics(sim)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a407f55",
   "metadata": {},
   "source": [
    "## 9. Save enriched backtest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f70dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"./data/backtest_results.csv\"\n",
    "sim.to_csv(out_path, index=False)\n",
    "print(f\"Saved backtest results to {out_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
