{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d4089b",
   "metadata": {},
   "source": [
    "# NFL Modeling with Betting Lines: nflfastR + RBSDM + The Odds API\n",
    "\n",
    "This notebook extends the end-to-end pipeline to:  \n",
    "- Export weekly predictions to CSV.  \n",
    "- Pull live betting lines from **The Odds API** for `americanfootball_nfl`, compute implied probabilities, and compare to model outputs.  \n",
    "\n",
    "Two spaces after periods per your preference.  Hyphens instead of em dashes.  \n",
    "\n",
    "**Prereqs:** `pip install nfl_data_py pandas requests scikit-learn matplotlib` and an Odds API key in `ODDS_API_KEY`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914f775",
   "metadata": {},
   "source": [
    "## 1. Setup and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246601b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running locally, uncomment as needed.\n",
    "# %pip install -U pandas numpy scikit-learn matplotlib requests nfl_data_py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258ae9c",
   "metadata": {},
   "source": [
    "## 2. Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, time, math, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from nfl_data_py import import_pbp_data, import_schedules\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c5ac9",
   "metadata": {},
   "source": [
    "## 3. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONS = list(range(2019, 2025))\n",
    "PREDICT_SEASON = 2024\n",
    "PREDICT_WEEK = 10\n",
    "\n",
    "RBSDM_URL = \"https://rbsdm.com/stats/stats.csv\"\n",
    "\n",
    "# Paths\n",
    "PRED_DIR = \"./data/weekly_predictions\"\n",
    "os.makedirs(PRED_DIR, exist_ok=True)\n",
    "\n",
    "# The Odds API\n",
    "ODDS_API_KEY = os.environ.get(\"ODDS_API_KEY\", None)  # set in your shell: export ODDS_API_KEY=...\n",
    "ODDS_SPORT = \"americanfootball_nfl\"  # The Odds API sport key\n",
    "ODDS_REGION = \"us\"                   # regions: us, uk, eu, au\n",
    "ODDS_MARKETS = \"h2h,spreads,totals\"  # choose what to pull\n",
    "ODDS_ODDSFORMAT = \"american\"         # american, decimal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4def1d5",
   "metadata": {},
   "source": [
    "## 4. Load data and engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pbp and schedules\n",
    "pbp = import_pbp_data(SEASONS)\n",
    "pbp = pbp.loc[pbp[\"play_type\"].notna()].copy()\n",
    "\n",
    "sched = import_schedules(SEASONS)\n",
    "sched = sched.assign(home_win = (sched[\"result\"] > 0).astype(int))\n",
    "sched_small = sched[[\n",
    "    \"game_id\",\"season\",\"week\",\"game_type\",\"gameday\",\n",
    "    \"home_team\",\"away_team\",\"home_score\",\"away_score\",\"home_win\"\n",
    "]].copy()\n",
    "sched_small = sched_small.loc[sched_small[\"game_type\"] == \"REG\"].reset_index(drop=True)\n",
    "\n",
    "# Offense aggregates\n",
    "off_agg = (\n",
    "    pbp.groupby([\"season\",\"week\",\"posteam\"], as_index=False)\n",
    "       .agg(\n",
    "           off_plays=(\"play_id\",\"count\"),\n",
    "           off_epa_mean=(\"epa\",\"mean\"),\n",
    "           off_success=(\"success\",\"mean\"),\n",
    "           off_yards_gained=(\"yards_gained\",\"mean\"),\n",
    "           off_pass_rate=(\"pass\",\"mean\"),\n",
    "           off_rush_rate=(\"rush\",\"mean\")\n",
    "       ).rename(columns={\"posteam\":\"team\"})\n",
    ")\n",
    "\n",
    "# Defense aggregates\n",
    "def_agg = (\n",
    "    pbp.groupby([\"season\",\"week\",\"defteam\"], as_index=False)\n",
    "       .agg(\n",
    "           def_plays=(\"play_id\",\"count\"),\n",
    "           def_epa_mean=(\"epa\",\"mean\"),\n",
    "           def_success=(\"success\",\"mean\"),\n",
    "           def_yards_gained=(\"yards_gained\",\"mean\"),\n",
    "           def_pass_rate=(\"pass\",\"mean\"),\n",
    "           def_rush_rate=(\"rush\",\"mean\")\n",
    "       ).rename(columns={\"defteam\":\"team\"})\n",
    ")\n",
    "\n",
    "team_week = pd.merge(off_agg, def_agg, on=[\"season\",\"week\",\"team\"], how=\"outer\")\n",
    "\n",
    "def add_group_rolls(df, group_col=\"team\"):\n",
    "    df = df.sort_values([\"season\",\"week\"]).copy()\n",
    "    df[\"season_week_index\"] = (df[\"season\"] - df[\"season\"].min()) * 18 + df[\"week\"]\n",
    "    df = df.sort_values([group_col, \"season_week_index\"])\n",
    "    num_cols = [c for c in df.columns if c not in [group_col,\"season\",\"week\",\"season_week_index\"]]\n",
    "    for col in num_cols:\n",
    "        df[f\"{col}_lag1\"]  = df.groupby(group_col)[col].shift(1)\n",
    "        df[f\"{col}_roll3\"] = df.groupby(group_col)[col].shift(1).rolling(3).mean()\n",
    "        df[f\"{col}_roll5\"] = df.groupby(group_col)[col].shift(1).rolling(5).mean()\n",
    "    return df\n",
    "\n",
    "team_week = add_group_rolls(team_week, \"team\")\n",
    "lag_cols = [c for c in team_week.columns if c.endswith((\"_lag1\",\"_roll3\",\"_roll5\"))]\n",
    "team_week_lagged = team_week[[\"season\",\"week\",\"team\"] + lag_cols].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8b9eb",
   "metadata": {},
   "source": [
    "## 5. RBSDM join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ada440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(RBSDM_URL, timeout=30)\n",
    "r.raise_for_status()\n",
    "import io\n",
    "rbsdm = pd.read_csv(io.StringIO(r.text))\n",
    "\n",
    "possible_cols = [c for c in rbsdm.columns if c.lower() in {\n",
    "    \"team\",\"season\",\"off_epa\",\"def_epa\",\"off_success\",\"def_success\",\"off_pass_epa\",\"off_rush_epa\",\"def_pass_epa\",\"def_rush_epa\"\n",
    "}]\n",
    "if \"team\" not in possible_cols:\n",
    "    possible_cols = [\"team\",\"season\",\"off_epa\",\"def_epa\",\"off_success\",\"def_success\",\"off_pass_epa\",\"off_rush_epa\",\"def_pass_epa\",\"def_rush_epa\"]\n",
    "rbsdm_small = rbsdm[[c for c in possible_cols if c in rbsdm.columns]].copy()\n",
    "if \"team\" in rbsdm_small.columns:\n",
    "    rbsdm_small = rbsdm_small.rename(columns={\"team\":\"team_full\"})\n",
    "\n",
    "abbr_to_full = {\n",
    "    \"ARI\":\"Arizona Cardinals\",\"ATL\":\"Atlanta Falcons\",\"BAL\":\"Baltimore Ravens\",\"BUF\":\"Buffalo Bills\",\n",
    "    \"CAR\":\"Carolina Panthers\",\"CHI\":\"Chicago Bears\",\"CIN\":\"Cincinnati Bengals\",\"CLE\":\"Cleveland Browns\",\n",
    "    \"DAL\":\"Dallas Cowboys\",\"DEN\":\"Denver Broncos\",\"DET\":\"Detroit Lions\",\"GB\":\"Green Bay Packers\",\n",
    "    \"HOU\":\"Houston Texans\",\"IND\":\"Indianapolis Colts\",\"JAX\":\"Jacksonville Jaguars\",\"KC\":\"Kansas City Chiefs\",\n",
    "    \"LV\":\"Las Vegas Raiders\",\"LAC\":\"Los Angeles Chargers\",\"LAR\":\"Los Angeles Rams\",\"MIA\":\"Miami Dolphins\",\n",
    "    \"MIN\":\"Minnesota Vikings\",\"NE\":\"New England Patriots\",\"NO\":\"New Orleans Saints\",\"NYG\":\"New York Giants\",\n",
    "    \"NYJ\":\"New York Jets\",\"PHI\":\"Philadelphia Eagles\",\"PIT\":\"Pittsburgh Steelers\",\"SEA\":\"Seattle Seahawks\",\n",
    "    \"SF\":\"San Francisco 49ers\",\"TB\":\"Tampa Bay Buccaneers\",\"TEN\":\"Tennessee Titans\",\"WAS\":\"Washington Commanders\"\n",
    "}\n",
    "teams_map = pd.DataFrame({\"team\": list(abbr_to_full.keys()), \"team_full\": list(abbr_to_full.values())})\n",
    "\n",
    "team_week_enriched = team_week_lagged.merge(teams_map, on=\"team\", how=\"left\").merge(\n",
    "    rbsdm_small, on=[\"team_full\",\"season\"], how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384b3f9",
   "metadata": {},
   "source": [
    "## 6. Game-level assembly and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_game_table(sched_small, team_week_enriched):\n",
    "    # Prefix features per side\n",
    "    def join_side(prefix):\n",
    "        side = team_week_enriched.copy()\n",
    "        side = side.rename(columns={\"team\": f\"{prefix}_team\"})\n",
    "        # Prefix all except keys\n",
    "        cols = [c for c in side.columns if c not in [\"season\",\"week\",f\"{prefix}_team\",\"team_full\"]]\n",
    "        side = side.rename(columns={c: f\"{prefix}_{c}\" for c in cols})\n",
    "        return side\n",
    "\n",
    "    home = join_side(\"home\")\n",
    "    away = join_side(\"away\")\n",
    "\n",
    "    games = sched_small.merge(\n",
    "        home, left_on=[\"season\",\"week\",\"home_team\"], right_on=[\"season\",\"week\",\"home_team\"], how=\"left\"\n",
    "    ).merge(\n",
    "        away, left_on=[\"season\",\"week\",\"away_team\"], right_on=[\"season\",\"week\",\"away_team\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "    games[\"y_home_win\"] = games[\"home_win\"].astype(int)\n",
    "\n",
    "    feat_cols = [c for c in games.columns if any(c.startswith(p) for p in [\"home_\",\"away_\"])]\n",
    "    X = games[feat_cols].select_dtypes(include=[np.number]).copy()\n",
    "    y = games[\"y_home_win\"].copy()\n",
    "\n",
    "    # keep columns that are present in most rows\n",
    "    min_non_na = int(0.8 * len(X))\n",
    "    keep_cols = [c for c in X.columns if X[c].notna().sum() >= min_non_na]\n",
    "    X = X[keep_cols]\n",
    "    mask = X.notna().all(axis=1).values\n",
    "    return games[mask].reset_index(drop=True), X[mask], y[mask], keep_cols\n",
    "\n",
    "games_valid, X, y, keep_cols = prep_game_table(sched_small, team_week_enriched)\n",
    "\n",
    "last_season = max(SEASONS)\n",
    "train_mask = games_valid[\"season\"] < last_season\n",
    "test_mask  = games_valid[\"season\"] == last_season\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "logit = LogisticRegression(max_iter=250, solver=\"lbfgs\")\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "logit_proba = logit.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_proba = gb.predict_proba(X_test)[:,1]\n",
    "\n",
    "def eval_metrics(y_true, y_pred_proba, threshold=0.5, label=\"model\"):\n",
    "    from sklearn.metrics import roc_auc_score, brier_score_loss, accuracy_score\n",
    "    auc  = roc_auc_score(y_true, y_pred_proba)\n",
    "    brier = brier_score_loss(y_true, y_pred_proba)\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return {\"label\": label, \"AUC\": auc, \"Brier\": brier, \"Accuracy@0.5\": acc}\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    eval_metrics(y_test, logit_proba, label=\"Logistic Regression\"),\n",
    "    eval_metrics(y_test, gb_proba,   label=\"Gradient Boosting\")\n",
    "])\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c664fd",
   "metadata": {},
   "source": [
    "## 7. Weekly predictions and CSV export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87baabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_week(games_valid, X_cols, scaler, logit, gb, season, week, out_dir=PRED_DIR):\n",
    "    g = games_valid[(games_valid[\"season\"] == season) & (games_valid[\"week\"] == week)].copy()\n",
    "    if g.empty:\n",
    "        print(\"No games found for that season and week.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    X_week = g[X_cols].copy()\n",
    "    X_week_scaled = scaler.transform(X_week)\n",
    "\n",
    "    g[\"proba_home_logit\"] = logit.predict_proba(X_week_scaled)[:,1]\n",
    "    g[\"proba_home_gb\"]    = gb.predict_proba(X_week)[:,1]\n",
    "    g[\"pick_logit_home\"]  = (g[\"proba_home_logit\"] >= 0.5).astype(int)\n",
    "    g[\"pick_gb_home\"]     = (g[\"proba_home_gb\"] >= 0.5).astype(int)\n",
    "\n",
    "    cols = [\"season\",\"week\",\"gameday\",\"home_team\",\"away_team\",\"home_win\",\n",
    "            \"proba_home_logit\",\"proba_home_gb\",\"pick_logit_home\",\"pick_gb_home\"]\n",
    "    out = g[cols].sort_values([\"week\",\"home_team\"]).reset_index(drop=True)\n",
    "\n",
    "    # Save CSV\n",
    "    fname = f\"{out_dir}/predictions_{season}_wk{week}.csv\"\n",
    "    out.to_csv(fname, index=False)\n",
    "    print(f\"Saved predictions to {fname}\")\n",
    "    return out\n",
    "\n",
    "preds_this_week = predict_week(games_valid, keep_cols, scaler, logit, gb, PREDICT_SEASON, PREDICT_WEEK, PRED_DIR)\n",
    "preds_this_week.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8192e6",
   "metadata": {},
   "source": [
    "## 8. Odds helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied probabilities from moneylines.  American odds to implied probability without vigorish removal.\n",
    "def moneyline_to_prob(ml):\n",
    "    if ml is None or pd.isna(ml):\n",
    "        return np.nan\n",
    "    ml = float(ml)\n",
    "    if ml > 0:\n",
    "        return 100.0 / (ml + 100.0)\n",
    "    else:\n",
    "        return -ml / (-ml + 100.0)\n",
    "\n",
    "# Remove vig to normalize to 1.0.  If both sides given.\n",
    "def normalize_two_way(p_home, p_away):\n",
    "    if np.isnan(p_home) or np.isnan(p_away):\n",
    "        return p_home, p_away\n",
    "    s = p_home + p_away\n",
    "    if s <= 0:\n",
    "        return p_home, p_away\n",
    "    return p_home / s, p_away / s\n",
    "\n",
    "# Light team name harmonization for The Odds API vs nflfastR abbreviations\n",
    "ODDS_TEAM_NAME_TO_ABBR = {\n",
    "    \"Arizona Cardinals\":\"ARI\",\"Atlanta Falcons\":\"ATL\",\"Baltimore Ravens\":\"BAL\",\"Buffalo Bills\":\"BUF\",\n",
    "    \"Carolina Panthers\":\"CAR\",\"Chicago Bears\":\"CHI\",\"Cincinnati Bengals\":\"CIN\",\"Cleveland Browns\":\"CLE\",\n",
    "    \"Dallas Cowboys\":\"DAL\",\"Denver Broncos\":\"DEN\",\"Detroit Lions\":\"DET\",\"Green Bay Packers\":\"GB\",\n",
    "    \"Houston Texans\":\"HOU\",\"Indianapolis Colts\":\"IND\",\"Jacksonville Jaguars\":\"JAX\",\"Kansas City Chiefs\":\"KC\",\n",
    "    \"Las Vegas Raiders\":\"LV\",\"Los Angeles Chargers\":\"LAC\",\"Los Angeles Rams\":\"LAR\",\"Miami Dolphins\":\"MIA\",\n",
    "    \"Minnesota Vikings\":\"MIN\",\"New England Patriots\":\"NE\",\"New Orleans Saints\":\"NO\",\"New York Giants\":\"NYG\",\n",
    "    \"New York Jets\":\"NYJ\",\"Philadelphia Eagles\":\"PHI\",\"Pittsburgh Steelers\":\"PIT\",\"Seattle Seahawks\":\"SEA\",\n",
    "    \"San Francisco 49ers\":\"SF\",\"Tampa Bay Buccaneers\":\"TB\",\"Tennessee Titans\":\"TEN\",\"Washington Commanders\":\"WAS\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12424de",
   "metadata": {},
   "source": [
    "## 9. Pull The Odds API lines for a date range or week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a79f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_odds_oddsapi(api_key, sport=ODDS_SPORT, regions=ODDS_REGION, markets=ODDS_MARKETS, odds_format=ODDS_ODDSFORMAT):\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"ODDS_API_KEY not set.  Set env var ODDS_API_KEY before running.\")\n",
    "    url = f\"https://api.the-odds-api.com/v4/sports/{sport}/odds/\"\n",
    "    params = {\n",
    "        \"regions\": regions,\n",
    "        \"markets\": markets,\n",
    "        \"oddsFormat\": odds_format,\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data\n",
    "\n",
    "def odds_to_frame(data):\n",
    "    # Flatten The Odds API response to a reasonable DataFrame with best available prices per book.\n",
    "    rows = []\n",
    "    for game in data:\n",
    "        commence_time = game.get(\"commence_time\")\n",
    "        home = game.get(\"home_team\")\n",
    "        away = game.get(\"away_team\")\n",
    "        # pick best moneyline across bookmakers for both sides\n",
    "        ml_home, ml_away = np.nan, np.nan\n",
    "        spread_home, spread_away = np.nan, np.nan\n",
    "        total_points = np.nan\n",
    "\n",
    "        for bm in game.get(\"bookmakers\", []):\n",
    "            for market in bm.get(\"markets\", []):\n",
    "                mk = market.get(\"key\")\n",
    "                outcomes = market.get(\"outcomes\", [])\n",
    "                if mk == \"h2h\":\n",
    "                    # moneyline\n",
    "                    for o in outcomes:\n",
    "                        if o.get(\"name\") == home:\n",
    "                            ml_home = np.nanmax([ml_home, o.get(\"price\")])\n",
    "                        elif o.get(\"name\") == away:\n",
    "                            ml_away = np.nanmax([ml_away, o.get(\"price\")])\n",
    "                elif mk == \"spreads\":\n",
    "                    # take home line where outcome name == home\n",
    "                    for o in outcomes:\n",
    "                        if o.get(\"name\") == home:\n",
    "                            spread_home = o.get(\"point\")\n",
    "                        elif o.get(\"name\") == away:\n",
    "                            spread_away = o.get(\"point\")\n",
    "                elif mk == \"totals\":\n",
    "                    # just capture a representative total\n",
    "                    if outcomes:\n",
    "                        total_points = outcomes[0].get(\"point\", total_points)\n",
    "\n",
    "        rows.append({\n",
    "            \"commence_time\": commence_time,\n",
    "            \"home_name\": home,\n",
    "            \"away_name\": away,\n",
    "            \"ml_home\": ml_home,\n",
    "            \"ml_away\": ml_away,\n",
    "            \"spread_home\": spread_home,\n",
    "            \"spread_away\": spread_away,\n",
    "            \"total_points\": total_points\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example fetch.  Comment out if you prefer to skip during dev.\n",
    "if ODDS_API_KEY:\n",
    "    raw = fetch_odds_oddsapi(ODDS_API_KEY)\n",
    "    odds_df = odds_to_frame(raw)\n",
    "    # Map names to abbreviations\n",
    "    odds_df[\"home_team\"] = odds_df[\"home_name\"].map(ODDS_TEAM_NAME_TO_ABBR)\n",
    "    odds_df[\"away_team\"] = odds_df[\"away_name\"].map(ODDS_TEAM_NAME_TO_ABBR)\n",
    "    print(f\"Pulled {len(odds_df)} games from The Odds API.\")\n",
    "    display(odds_df.head())\n",
    "else:\n",
    "    print(\"ODDS_API_KEY not found in environment.  Set it to enable live odds fetching.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e64343",
   "metadata": {},
   "source": [
    "## 10. Join odds to predictions and compute edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_odds_to_preds(preds_df, odds_df, season, week):\n",
    "    # Merge on home_team and away_team.  If multiple rows per matchup in odds, take the first.\n",
    "    o = odds_df.drop_duplicates(subset=[\"home_team\",\"away_team\"]).copy()\n",
    "\n",
    "    out = preds_df.merge(\n",
    "        o[[\"home_team\",\"away_team\",\"ml_home\",\"ml_away\",\"spread_home\",\"spread_away\",\"total_points\"]],\n",
    "        on=[\"home_team\",\"away_team\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Implied probabilities from moneylines\n",
    "    out[\"impl_home\"] = out[\"ml_home\"].apply(moneyline_to_prob)\n",
    "    out[\"impl_away\"] = out[\"ml_away\"].apply(moneyline_to_prob)\n",
    "    out[\"impl_home_norm\"], out[\"impl_away_norm\"] = zip(*out.apply(lambda r: normalize_two_way(r[\"impl_home\"], r[\"impl_away\"]), axis=1))\n",
    "\n",
    "    # Edge vs model probabilities\n",
    "    out[\"edge_logit_home\"] = out[\"proba_home_logit\"] - out[\"impl_home_norm\"]\n",
    "    out[\"edge_gb_home\"]    = out[\"proba_home_gb\"]    - out[\"impl_home_norm\"]\n",
    "\n",
    "    # Save\n",
    "    fname = f\"{PRED_DIR}/predictions_with_odds_{season}_wk{week}.csv\"\n",
    "    out.to_csv(fname, index=False)\n",
    "    print(f\"Saved predictions with odds to {fname}\")\n",
    "    return out\n",
    "\n",
    "if ODDS_API_KEY:\n",
    "    preds = preds_this_week if 'preds_this_week' in globals() else None\n",
    "    if preds is None or preds.empty:\n",
    "        preds = predict_week(games_valid, keep_cols, scaler, logit, gb, PREDICT_SEASON, PREDICT_WEEK, PRED_DIR)\n",
    "    joined = join_odds_to_preds(preds, odds_df, PREDICT_SEASON, PREDICT_WEEK)\n",
    "    display(joined.sort_values(\"edge_gb_home\", ascending=False).head(10))\n",
    "else:\n",
    "    print(\"Skipping join since ODDS_API_KEY not set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df5ea1",
   "metadata": {},
   "source": [
    "## 11. Quick visualization: model vs implied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ODDS_API_KEY and 'joined' in globals():\n",
    "    plt.figure()\n",
    "    plt.scatter(joined[\"impl_home_norm\"], joined[\"proba_home_gb\"], alpha=0.7)\n",
    "    plt.xlabel(\"Implied probability home (normalized)\")\n",
    "    plt.ylabel(\"Model probability home - Gradient Boosting\")\n",
    "    plt.title(\"Market implied vs model probability - home side\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No joined data to plot.  Ensure ODDS_API_KEY is set and odds were fetched.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd84a8",
   "metadata": {},
   "source": [
    "## 12. Notes\n",
    "\n",
    "- The Odds API has per-minute rate limits and daily quotas.  Cache your results locally for repeat runs.  \n",
    "- Moneyline implied probabilities are normalized here to remove book vig.  \n",
    "- Mapping between Odds API team names and nflfastR abbreviations is manual.  Adjust if the provider updates naming.  \n",
    "- Consider incorporating closing spreads and totals as model features for calibration improvements.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
